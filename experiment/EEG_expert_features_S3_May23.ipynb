{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pkldV_zTyuH"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "#%matplotlib inline\n",
        "#!pip3 install pyriemann\n",
        "#!pip3 install mne\n",
        "#!conda create --name=new_environment_name python=3\n",
        "#!conda activate new_environment_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY2Gjq6bAwRs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#--- \n",
        "import pandas as pd\n",
        "import scipy.io as sio # Download mat files\n",
        "from google.colab import drive # Mount the drive\n",
        "from google.colab import files # Save the experimental results to the drive \n",
        "import sys # To print error messages\n",
        "#---\n",
        "#import mne # MNE and PyRiemann are tha main tools for classification\n",
        "#from mne import io\n",
        "#from mne.datasets import sample\n",
        "#from pyriemann.estimation import XdawnCovariances\n",
        "#from pyriemann.tangentspace import TangentSpace\n",
        "#---\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import make_pipeline\n",
        "#---\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "#from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "#from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.gaussian_process.kernels import Matern, RationalQuadratic, ExpSineSquared, DotProduct, WhiteKernel\n",
        "#---\n",
        "from sklearn.metrics import RocCurveDisplay # Plot the ROC \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt2\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.linear_model import RidgeCV\n",
        "#--- \n",
        "from sklearn.preprocessing import MinMaxScaler # Import various scalers \n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "#--- \n",
        "from sklearn.decomposition import PCA         # PCA, transfoemations and grid search\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.pipeline import Pipeline # See above\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q0nddTCBNu_"
      },
      "outputs": [],
      "source": [
        "# Three models selected and sorted. They return probabilistic values of classes\n",
        "def classifiers_3():\n",
        "  names = [\n",
        "      \"Logistic Regression\",\n",
        "      \"Gaussian Process\",\n",
        "      \"Naive Bayes\",\n",
        "      ]\n",
        "  classifiers = [\n",
        "      LogisticRegression(),\n",
        "      GaussianProcessClassifier(1.0 * RBF(1.0)), \n",
        "      GaussianNB(),\n",
        "      ]\n",
        "  return names, classifiers\n",
        "# --- \n",
        "# Basic kernels: RBF, Maternel, Rational Quadratic, Dot Product, Exponential Sine Quadratic.\n",
        "# Composite kernels: White, Ridge, Periodic, Irregular, Noisy, Rumble.\n",
        "def classifiers_GP():\n",
        "  classifiers = [\n",
        "      LogisticRegression(),\n",
        "      GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "      GaussianProcessClassifier(kernel=Matern(length_scale=1.0, nu=1.5)),\n",
        "      GaussianProcessClassifier(kernel=RationalQuadratic(length_scale=1.0, alpha=1.0, alpha_bounds=(1e-5, 1e5))),\n",
        "      GaussianProcessClassifier(kernel=DotProduct(sigma_0=1.0, sigma_0_bounds=(1e-5, 1e5))),\n",
        "      #GaussianProcessClassifier(kernel = 1.0 * ExpSineSquared(1.0, 5.0, periodicity_bounds=(1e-2, 1e1))),    \n",
        "      #GaussianProcessClassifier(kernel=ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=(1e-5, 1e5))), \n",
        "      # Composite\n",
        "      #GaussianProcessClassifier(kernel = 1.0 * ExpSineSquared(1.0, 5.0, periodicity_bounds=(1e-2, 1e1)) + WhiteKernel(1e-1)),\n",
        "      #GaussianProcessClassifier(kernel = ExpSineSquared()),\n",
        "      #GaussianProcessClassifier(kernel = (2.0**2 * RBF(length_scale=100.0) * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\"))),\n",
        "      GaussianProcessClassifier(kernel = 0.5**2 * RationalQuadratic(length_scale=1.0, alpha=1.0)),\n",
        "      GaussianProcessClassifier(kernel =  0.1**2 * RBF(length_scale=0.1) + WhiteKernel(noise_level=0.1**2, noise_level_bounds=(1e-5, 1e5))),\n",
        "      #GaussianProcessClassifier(kernel =  44.8**2 * RBF(length_scale=51.6) + 2.64**2 * RBF(length_scale=91.5) * ExpSineSquared(length_scale=1.48, periodicity=1) + 0.536**2 * RationalQuadratic(alpha=2.89, length_scale=0.968) + 0.188**2 * RBF(length_scale=0.122) + WhiteKernel(noise_level=0.0367)),\n",
        "      ]\n",
        "  names = [\n",
        "      \"Logistic Regression\",\n",
        "      \"Gaussian RBF\",\n",
        "      \"GP Maternel\",\n",
        "      \"GP Rational Quadratic\",\n",
        "      \"GP Dot Product\",\n",
        "      #\"Exponential Sine Quadratic\",\n",
        "      # Cpmposite\n",
        "      #\"GP White\",\n",
        "      #\"GP Ridge\",\n",
        "      #\"GP Periodic\",\n",
        "      \"GP Irregular\",\n",
        "      \"GP Noisy\",\n",
        "      #\"GP Rumble\",\n",
        "      ]\n",
        "  return names, classifiers\n",
        "# --- Assert tne classifiers\n",
        "names, classifiers = classifiers_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrY72zwbBrvK",
        "outputId": "fa753d02-bfc0-4a4a-c6c5-680272d85498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/EEG\n",
            " \u001b[0m\u001b[01;34marchiveCodeApr14\u001b[0m/\n",
            " \u001b[01;34marchiveCodeApr28\u001b[0m/\n",
            "\u001b[01;34m'archive EEG pdf'\u001b[0m/\n",
            "'Colab clone arl-eegmodels.git'\n",
            "'Colab clone HTNet'\n",
            "'Copy of EEG expert features S3 May 23 (1).ipynb'\n",
            "'Copy of EEG expert features S3 May 23.ipynb'\n",
            " \u001b[01;34mDataApr26\u001b[0m/\n",
            " \u001b[01;34mDataApr28\u001b[0m/\n",
            "'EEG class balance [Apr 19].gdoc'\n",
            "'EEG classifier comparison Apr28.ipynb'\n",
            "'EEG ERP experiment [Apr 12].gdoc'\n",
            "'EEG ERP feature extraction [May 12].gdoc'\n",
            "'EEG exhaustive model comparison [Apr 26].gdoc'\n",
            "'EEG expert-engineered features [May 23].gdoc'\n",
            "'EEG expert features May 16.ipynb'\n",
            "'EEG expert features S3 May 23.ipynb'\n",
            " eeg_May19.mat\n",
            " eeg_May23_unfilt.mat\n",
            " EEG-model-comparison-basic.ipynb\n",
            "'EEG PlotAppendix [May 2].pdf'\n",
            "'EEG research plans [Apr 4].gdoc'\n",
            "'EEG search over engineered features [May 30].gdoc'\n",
            "'EEG SOW W1: Proof of Concept Analysis [May 5].gslides'\n",
            "'EEG tables temporary.gsheet'\n",
            "'EEG  three classifiers reported Apr30.ipynb'\n",
            "'EEG time-window exploring [May 9].gdoc'\n",
            "'EEG user behavior analysis [May 2].gdoc'\n",
            " Run_D4_inColab.ipynb\n",
            " \u001b[01;34mSamokhina2022P300\u001b[0m/\n",
            " step1_collect_from_neurop.m\n"
          ]
        }
      ],
      "source": [
        "# The data files are in the drive\n",
        "drive.mount('/content/drive')\n",
        "%cd  '/content/drive/MyDrive/EEG/'\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqTmhyKtCY7_"
      },
      "outputs": [],
      "source": [
        "# Expert-generated features\n",
        "# Basic set \n",
        "def fea_basic():\n",
        "  namel = ('PO9', 'PO10', 'PO7', 'PO8', 'PO7', 'PO8', 'AF7', 'AF7')\n",
        "  elec  = (128, 42, 10, 39, 10, 39, 94, 94)\n",
        "  elec  = tuple(_ - 1 for _ in elec) # Set of electrode indexes\n",
        "  start = np.array([110, 110, 200, 200, 410, 410, 500, 400]) * 0.001\n",
        "  stop  = np.array([160, 160, 410, 410, 650, 650, 800, 750]) * 0.001\n",
        "  return namel, elec, start, stop\n",
        "# Basic set with neighbours\n",
        "def fea_nbr1():\n",
        "  namel = ('PO9', 'PO10', 'PO7', 'PO7', 'PO7', 'PO8', 'PO8', 'PO8', 'PO7', 'PO7', 'PO7', 'PO8', 'PO8', 'PO8', 'AF7', 'AF7', 'AF7', 'AF7')\n",
        "  elec  = (128, 42, 9, 10, 11, 38, 39, 40, 9, 10, 11, 38, 39, 40, 94, 95, 94, 95)\n",
        "  elec  = tuple(_ - 1 for _ in elec) # Set of electrode indexes\n",
        "  start = np.array([110, 110, 200, 200, 200, 200, 200, 200, 410, 410, 410, 410, 410, 410, 500, 500, 400, 400]) * 0.001\n",
        "  stop  = np.array([160, 160, 410, 410, 410, 410, 410, 410, 650, 650, 650, 650, 650, 650, 800, 800, 750, 750]) * 0.001\n",
        "  return namel, elec, start, stop\n",
        "# Timing from the basic set for all electrodes\n",
        "def fea_all():\n",
        "  namel = ('ALL', 'ALL', 'ALL', 'ALL')#ALL\n",
        "  elec  = ()\n",
        "  start = np.array([110, 200, 410, 500]) * 0.001#, 400 \n",
        "  stop  = np.array([160, 410, 650, 800]) * 0.001#, 750\n",
        "  return namel, elec, start, stop\n",
        "#FREQ_ = 256 # Hz for conversion\n",
        "namel, elec, start, stop = fea_basic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emq2oJbmEnTP"
      },
      "outputs": [],
      "source": [
        "# S3 dataset, the variables:\n",
        "# 1) dataX, dataY, Users, timeY for each user assigned to each event\n",
        "# 2) timeX, nameElec, posElec   for all users, the experiment setup \n",
        "mat_fname = 'eeg_May23_unfilt.mat'#'eeg_May19.mat'\n",
        "mat_contents = sio.loadmat(mat_fname)\n",
        "dataX = mat_contents['dataX']                   # The design matrix Events x Electrodes x Time\n",
        "dataY = np.squeeze(mat_contents['dataY'])       # A class for each Event\n",
        "dataU = np.squeeze(mat_contents['dataU'])       # A username for each Event\n",
        "# timeY = mat_contents['timeY'] # Not needed here\n",
        "# Predefined indexes of columns in the dataY structure, see the Matlab part \n",
        "# List of all available users in the data\n",
        "users    = np.squeeze(mat_contents['nameUsers'])\n",
        "timeline = np.squeeze(mat_contents['timeX'])\n",
        "# posElec = mat_contents['posElec']   # Not needed here\n",
        "# nameElec = mat_contents['nameElec'] # ditto\n",
        "# Claffify each event (trial) as two classes Old word versus New word in the Recognition task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9VlkFKwTuT9"
      },
      "outputs": [],
      "source": [
        "# Updated after feat_aver for S3 data with embedded timeline (instead o freq)\n",
        "def feat_mean(ts, start, stop, timeline):\n",
        "  # Get a piece of time series ts\n",
        "  # Example\n",
        "  # ts = np.array([1, 2, 3, 11, 22, 33, 111, 222, 333, 1111, 2222, 3333])\n",
        "  # timeline = range(0,len(ts))\n",
        "  # start = -6 \n",
        "  # stop = 35\n",
        "  # len(ts) == len(timeline)\n",
        "  # aver, feaseg = feat_mean(ts, start, stop, timeline)\n",
        "  # print(feaseg)\n",
        "  if start >= stop or start < timeline[0] or stop > timeline[-1]:\n",
        "    sys.stderr.write(f'Start-stop mismatch the timeline! start: {start}, stop: {stop}, timeline[0]: {timeline[0]}, timeline[-1]: {timeline[-1]}')\n",
        "  # Make a feature, here average it\n",
        "  istart = np.searchsorted(timeline, start)\n",
        "  istop  = np.searchsorted(timeline, stop, side='right') #- 1\n",
        "  feaseg = ts[istart : istop]\n",
        "  fea = np.average(feaseg)\n",
        "  return fea\n",
        "  # Also todo return the other features of a segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yfaaC8uFeom"
      },
      "outputs": [],
      "source": [
        "fX = []\n",
        "for matX in dataX: # Process each event, the matrix electrodes, time\n",
        "  for elc, sta, stp in zip(elec, start, stop):  # Get one time series\n",
        "    fea = feat_mean(matX[elc,:], sta, stp, timeline)\n",
        "    fX = np.append(fX,fea)\n",
        "fX = np.reshape(fX, (len(dataX), len(elec)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LfTvC9WU9Kmq"
      },
      "outputs": [],
      "source": [
        "# Prepare the design matrix and target vector \n",
        "# Four cases: \n",
        "# Correct events, All events\n",
        "# Selected users, All users\n",
        "# Expert electrodes, All electrodes\n",
        "# ---\n",
        "# Four classes 0 1 2 3  => two classes 0 1\n",
        "# 0 Old correct\n",
        "# 1 Old incorrect\n",
        "# 2 New correct \n",
        "# 3 New incorrect\n",
        "# --- \n",
        "# Select users\n",
        "# userselect = users \n",
        "users_all = np.array([1037, 1363, 2038, 7977, 1045, 1368, 6639, 7980, 1034, 1327, 1385, 7974])\n",
        "users_six = np.array([1158,1045,7980,1037,6639,1363]) # Six users with higher accuracy\n",
        "#print(f'Selected: {np.isin(users, userselect)}')\n",
        "class_all = np.array([0, 1, 2, 3])   # All four include incorrect responses\n",
        "class_two = np.array([0, 2])         # Only correct responses\n",
        "\n",
        "\n",
        "# --- Run the schedule \n",
        "users_list = (users_all, users_all, users_six, users_six)\n",
        "class_list = (class_all, class_two, class_all, class_two)\n",
        "for userselect, classelect in zip (users_list, class_list):\n",
        "  # Select users and classes\n",
        "  idx = (np.isin(dataU, userselect)) & (np.isin(dataY, classelect))\n",
        "  # Make dataset\n",
        "  Y = np.array([0 if _ <  2 else 1 for _ in dataY[idx]]) # Two classes in selected data\n",
        "  X = fX[idx]\n",
        "  print(f'Users: {userselect} --- Sample size: {len(Y)} --- Class balance: {sum(Y==0)} vs {sum(Y==1)}') # --- Events: {set(Y)} \n",
        "  classify(X, Y, names, classifiers)\n",
        "  select_seatures(X,Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtkndhjS9RgE"
      },
      "outputs": [],
      "source": [
        "# n_components = 5  # pick some components\n",
        "def classify(X,Y, names, classifiers):\n",
        "  for name, clf in zip(names, classifiers):\n",
        "    print(f'Classifier: {name}')\n",
        "    clf = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        # PCA(),\n",
        "        # XdawnCovariances(n_components),\n",
        "        # TangentSpace(metric=\"riemann\"),       \n",
        "        clf, #LogisticRegression(),\n",
        "        )\n",
        "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    # --- \n",
        "    for train_idx, test_idx in cv.split(X): \n",
        "      preds = np.zeros(len(Y))\n",
        "      y_train, y_test = Y[train_idx], Y[test_idx]\n",
        "      clf.fit(X[train_idx], y_train)\n",
        "      #preds[test_idx] = clf.predict(X[test_idx]) # Binary for accuracy\n",
        "      preds[test_idx] = clf.predict_proba(X[test_idx])[::,1] # Probabilty for AUC\n",
        "    fpr, tpr, _ = metrics.roc_curve(Y[test_idx], preds[test_idx])\n",
        "    auc = round(metrics.roc_auc_score(Y[test_idx], preds[test_idx]), 4)\n",
        "    plt.plot(fpr,tpr,label=name+\", AUC=\"+str(auc))\n",
        "  plt.rcParams['font.family'] = 'DejaVu Serif'\n",
        "  plt.rcParams['lines.linewidth'] = 2\n",
        "  #plt.rcParams['lines.markersize'] = 12\n",
        "  plt.rcParams['xtick.labelsize'] = 12#24\n",
        "  plt.rcParams['ytick.labelsize'] = 12#24\n",
        "  plt.rcParams['legend.fontsize'] = 8#24\n",
        "  #plt.rcParams['axes.titlesize'] = 36. \n",
        "  plt.rcParams['axes.labelsize'] = 12#24\n",
        "  plt.gca().set_aspect('equal')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTh1c9KF7VtT"
      },
      "outputs": [],
      "source": [
        "def select_seatures(X,Y):\n",
        "  feature_names = ('PO9: 110-160', 'PO10: 110-160', 'PO7: 200-410', 'PO8: 200-410', 'PO7: 410-650', 'PO8: 410-650', 'AF7: 500-800', 'AF7: 400-750')\n",
        "  feature_names = ('PO9-P1' ,'PO10-P1' ,'PO7-P2' ,'PO8-P2' ,'PO7-P3' ,'PO8-P3' ,'AF7-LNP' ,'AF7-LN')\n",
        "  ridge = RidgeCV(alphas=np.logspace(-6, 6, num=5)).fit(X, Y)\n",
        "  importance = np.abs(ridge.coef_)\n",
        "  feature_names = np.array(feature_names)\n",
        "  plt.bar(height=importance, x=feature_names)\n",
        "  plt.rcParams['font.family'] = 'DejaVu Serif'\n",
        "  plt.ylabel('Feature importance')\n",
        "  plt.rcParams['ytick.labelsize'] = 12#24\n",
        "  plt.xlabel('Electrodes and peaks are features')\n",
        "  plt.rcParams['xtick.labelsize'] = 9#24\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}